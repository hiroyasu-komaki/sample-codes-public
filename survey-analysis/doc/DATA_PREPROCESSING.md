# データ前処理の詳細

## 目次

1. [概要](#概要)
2. [前処理の流れ](#前処理の流れ)
3. [カラム数の変化](#カラム数の変化)
4. [エンコーディング](#エンコーディング)
5. [欠損値処理](#欠損値処理)
6. [標準化とリスケーリング](#標準化とリスケーリング)
7. [出力データの構造](#出力データの構造)

---

## 概要

データ前処理では、生成されたサンプルデータ（100行×23列）を機械学習や統計分析に適した形式（90行×76列）に変換します。

**前処理の目的:**
- カテゴリカル変数を数値に変換（エンコーディング）
- 欠損値を適切に処理
- 数値データを標準化して比較可能にする

---

## 前処理の流れ

```
元データ（100行×23列）
    ↓
① データ型の識別
    ↓
② 外れ値の検出
    ↓
③ エンコーディング
    ├─ 順序エンコーディング（5項目）
    ├─ One-hotエンコーディング（3項目→14列）
    └─ 複数選択の二値展開（2項目→10列）
    ↓
④ 欠損値処理（43個の欠損値）
    ├─ リストワイズ削除（5%未満）
    └─ 平均値補完（5%以上）
    ↓
⑤ 標準化とリスケーリング（12項目）
    ├─ 標準化（平均=0, 標準偏差=1）
    └─ リスケール（元の範囲、標準偏差=1）
    ↓
前処理済みデータ（90行×76列）
```

---

## カラム数の変化

### 総計: 23列 → 76列（+53列）

```
23列 (元のデータ)
+ 5列  (順序エンコーディング: _encoded)
+ 14列 (One-hotダミー変数)
+ 10列 (複数選択の二値変数)
+ 12列 (標準化カラム: _std)
+ 12列 (リスケールカラム: _rescaled)
────────────────────────
= 76列
```

### 詳細内訳

#### 1. 元のカラム: 23列

```
- respondent_id: 1列
- 回答者属性: 4列
  - department (部署)
  - position (役職)
  - years_of_service (勤続年数)
  - it_skill_level (ITスキルレベル)
  
- サービス利用状況: 3列
  - usage_frequency (利用頻度)
  - main_services (主な利用サービス)
  - inquiry_count (問い合わせ回数)
  
- 満足度評価: 8列
  - overall_satisfaction (総合満足度)
  - response_speed (対応スピード)
  - technical_competence (技術力)
  - explanation_clarity (説明の分かりやすさ)
  - service_politeness (サービスの丁寧さ)
  - system_stability (システム安定性)
  - security_measures (セキュリティ対策)
  - new_system_support (新システム導入支援)
  
- 重要度評価: 4列
  - response_speed_importance
  - technical_competence_importance
  - explanation_clarity_importance
  - service_politeness_importance
  
- 改善要望: 3列
  - most_improvement_needed (最も改善が必要な点)
  - additional_services (追加してほしいサービス)
  - future_relationship (今後の関係)
```

#### 2. エンコーディング: +29列

**順序エンコーディング: +5列**
```
元のカラム → エンコード後のカラム
────────────────────────────────
position                → position_encoded (1-4)
years_of_service        → years_of_service_encoded (1-5)
it_skill_level          → it_skill_level_encoded (1-5)
usage_frequency         → usage_frequency_encoded (1-5)
inquiry_count           → inquiry_count_encoded (0-4)
```

**One-hotダミー変数: +14列**
```
department (1列 → 5列)
├─ dept_営業部
├─ dept_製造部
├─ dept_管理部
├─ dept_人事部
└─ dept_その他

most_improvement_needed (1列 → 5列)
├─ improve_対応スピード
├─ improve_技術力向上
├─ improve_説明方法
├─ improve_システム安定性
└─ improve_その他

future_relationship (1列 → 4列)
├─ future_現状維持
├─ future_より密接な連携
├─ future_より自立的な利用
└─ future_その他
```

**複数選択の二値変数: +10列**
```
main_services (1列 → 6列)
├─ service_ヘルプデスク
├─ service_システム障害対応
├─ service_新システム導入支援
├─ service_PC・機器設定
├─ service_ネットワーク関連
└─ service_セキュリティ関連

additional_services (1列 → 4列)
├─ add_service_セルフサービス機能
├─ add_service_FAQ充実
├─ add_service_リモート支援
└─ add_service_研修・講習会
```

#### 3. 標準化・リスケール: +24列

**標準化カラム (_std): +12列**
- 満足度評価: 8列
- 重要度評価: 4列

**リスケールカラム (_rescaled): +12列**
- 満足度評価: 8列
- 重要度評価: 4列

---

## エンコーディング

### 1. 順序エンコーディング（Ordinal Encoding）

順序関係のあるカテゴリカル変数を数値に変換します。

**例: position（役職）**
```yaml
マッピング:
  一般職: 1
  主任・係長: 2
  課長・部長: 3
  役員: 4
```

**適用項目:**
- position（役職）: 1-4
- years_of_service（勤続年数）: 1-5
- it_skill_level（ITスキルレベル）: 1-5
- usage_frequency（利用頻度）: 1-5
- inquiry_count（問い合わせ回数）: 0-4

### 2. One-hotエンコーディング

順序関係のないカテゴリカル変数をダミー変数に変換します。

**例: department（部署）**
```
元データ:
  営業部, 製造部, 管理部, ...

変換後:
  dept_営業部  dept_製造部  dept_管理部  dept_人事部  dept_その他
  1           0           0           0           0
  0           1           0           0           0
  0           0           1           0           0
```

**適用項目:**
- department（部署）: 5個のダミー変数
- most_improvement_needed（最も改善が必要な点）: 5個のダミー変数
- future_relationship（今後の関係）: 4個のダミー変数

### 3. 複数選択の二値展開

複数選択可能な項目を二値変数に展開します。

**例: main_services（主な利用サービス）**
```
元データ:
  "ヘルプデスク,システム障害対応"

変換後:
  service_ヘルプデスク  service_システム障害対応  service_新システム導入支援  ...
  1                   1                       0                        ...
```

**適用項目:**
- main_services（主な利用サービス）: 6個の二値変数
- additional_services（追加してほしいサービス）: 4個の二値変数

---

## 欠損値処理

### 処理方針

```yaml
欠損率 < 5%: リストワイズ削除（行ごと削除）
欠損率 ≥ 5%: 平均値補完
```

### 実際の処理結果

**総欠損数: 43個**
- データサイズ: 100行 → 90行（10行削除）

**欠損値の内訳例:**
```
overall_satisfaction: 6件（6.0%）→ 平均値補完
response_speed: 8件（8.0%）→ 平均値補完
explanation_clarity: 4件（4.0%）→ リストワイズ削除
system_stability: 2件（2.1%）→ リストワイズ削除
new_system_support: 4件（4.3%）→ リストワイズ削除
```

### 補完値の計算

平均値補完の場合、欠損していないデータの平均値で補完します。

**例:**
```
overall_satisfaction の平均: 2.86
→ 欠損値を 2.86 で補完
```

---

## 標準化とリスケーリング

### 目的

異なるスケールのデータを比較可能にするため、標準化を行います。

**問題点:**
- 満足度評価: 1-5のスケール
- 重要度評価: 1-4のスケール
→ 直接比較が困難

**解決策:**
1. 標準化（平均=0, 標準偏差=1に変換）
2. リスケーリング（元の範囲に戻しつつ標準偏差=1を保持）

### 1. 標準化（Z-score標準化）

**計算式:**
```
標準化値 = (元の値 - 平均) / 標準偏差
```

**結果:**
- 平均: 0
- 標準偏差: 1

**例:**
```
overall_satisfaction:
  元の平均: 2.86, 標準偏差: 1.05
  ↓ 標準化
  overall_satisfaction_std:
    平均: 0.00, 標準偏差: 1.00
```

### 2. リスケーリング

標準化後のデータ（平均=0, 標準偏差=1）を元の範囲に戻します。

**計算式:**
```
リスケール値 = 標準化値 × 1.0 + 中心値

中心値 = (最大値 + 最小値) / 2
  - 満足度（1-5）: 中心値 = 3.0
  - 重要度（1-4）: 中心値 = 2.5
```

**結果:**
- 平均: 範囲の中心値（満足度=3.0, 重要度=2.5）
- 標準偏差: 1.0（全項目で統一）

**例:**
```
overall_satisfaction:
  元データ: 平均2.86, 標準偏差1.05
  ↓ 標準化
  _std: 平均0.00, 標準偏差1.00
  ↓ リスケール
  _rescaled: 平均3.00, 標準偏差1.00
```

### 前処理前後の統計比較

```
満足度評価の統計:
項目                    前処理前           前処理後（リスケール）
                      平均     標準偏差     平均     標準偏差
────────────────────────────────────────────────────────
overall_satisfaction  2.86     1.05     3.00     1.00
response_speed        2.92     0.96     3.00     1.00
technical_competence  3.00     1.04     3.00     1.00
...

重要度評価の統計:
項目                            前処理前           前処理後（リスケール）
                              平均     標準偏差     平均     標準偏差
────────────────────────────────────────────────────────────────
response_speed_importance     2.86     0.75     2.50     1.00
technical_competence_...      2.89     0.75     2.50     1.00
...
```

**変化のポイント:**
1. **平均の統一**: 満足度は3.0、重要度は2.5に統一
2. **標準偏差の統一**: 全て1.00に統一
3. **比較可能性**: 異なるスケールの項目を同じ基準で比較可能

---

## 出力データの構造

### 前処理済みデータ（76列）

**カラムの種類:**

1. **元のカラム（23列）**
   - respondent_id
   - 回答者属性（4列）
   - サービス利用状況（3列）
   - 満足度評価（8列）
   - 重要度評価（4列）
   - 改善要望（3列）

2. **エンコード済みカラム（29列）**
   - 順序エンコーディング（5列）: `*_encoded`
   - One-hotダミー変数（14列）: `dept_*`, `improve_*`, `future_*`
   - 複数選択二値変数（10列）: `service_*`, `add_service_*`

3. **標準化カラム（12列）**
   - `*_std`: 平均=0, 標準偏差=1（分析用）

4. **リスケールカラム（12列）**
   - `*_rescaled`: 元の範囲、標準偏差=1（直感的理解用）

### 用途別の使い分け

**分析に使用するカラム:**
```python
# 機械学習モデルの入力
features = [
    'position_encoded',           # 順序エンコード済み
    'dept_営業部', 'dept_製造部',  # One-hotダミー
    'service_ヘルプデスク',        # 複数選択二値
    'overall_satisfaction_std',   # 標準化済み（平均=0, 標準偏差=1）
    ...
]
```

**レポート・可視化に使用するカラム:**
```python
# グラフや表で表示
report_columns = [
    'department',                      # 元のカテゴリ
    'overall_satisfaction_rescaled',   # リスケール済み（元の範囲）
    ...
]
```

---

## まとめ

### 前処理の効果

1. **カテゴリカル変数の数値化**
   - 機械学習アルゴリズムで使用可能に

2. **欠損値の適切な処理**
   - データの完全性を保ちつつ、情報損失を最小化

3. **スケールの統一**
   - 異なる範囲のデータを比較可能に
   - 標準偏差=1で統一することで、影響度を公平に評価

4. **データ品質の向上**
   - 外れ値の検出と対処
   - データの一貫性を確保

### 出力されるファイル

- `csv/survey_preprocessed_data.csv`: 前処理済みデータ（90行×76列）
- `out/preprocessing_report.json`: 前処理の詳細レポート

前処理の詳細な設定は `config/survey_questions.yaml` で定義されています。
