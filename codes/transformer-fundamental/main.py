#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Transformer Attention å¯è¦–åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ 
ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
"""

import sys
import os

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from modules.transformer-pseudo import SimpleTransformer


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("Transformer Attention å¯è¦–åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ ")
    print("=" * 60)
    print()
    
    # Transformerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
    transformer = SimpleTransformer()
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    output_dir = "output"
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. æ–‡ç« ç†è§£ã®ãƒ—ãƒ­ã‚»ã‚¹
    print("ğŸ“– ã‚¹ãƒ†ãƒƒãƒ—1: æ–‡ç« ç†è§£ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’å¯è¦–åŒ–ä¸­...")
    text = "ç§ãŒå…¬åœ’ã‚’æ­©ã„ã¦ã„ã‚‹ã¨ãå‘ã“ã†ã‹ã‚‰çŠ¬ãŒæ­©ã„ã¦ããŸã€‚ç§ã¯ãã®çŠ¬ã‚’è¦‹ãŸã€‚"
    understanding_output = os.path.join(output_dir, "attention_understanding.png")
    attention_matrix = transformer.visualize_understanding(text, understanding_output)
    print()
    
    # 2. æ–‡ç« ç”Ÿæˆã®ãƒ—ãƒ­ã‚»ã‚¹
    print("âœï¸  ã‚¹ãƒ†ãƒƒãƒ—2: æ–‡ç« ç”Ÿæˆã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’å¯è¦–åŒ–ä¸­...")
    generation_output = os.path.join(output_dir, "attention_generation.png")
    transformer.visualize_generation(generation_output)
    print()
    
    # 3. è©³ç´°ãªç”Ÿæˆã‚¹ãƒ†ãƒƒãƒ—
    print("ğŸ” ã‚¹ãƒ†ãƒƒãƒ—3: 1ã¤ã®ç”Ÿæˆã‚¹ãƒ†ãƒƒãƒ—ã‚’è©³ç´°ã«å¯è¦–åŒ–ä¸­...")
    detail_output = os.path.join(output_dir, "attention_generation_detail.png")
    transformer.visualize_detailed_generation_step(detail_output)
    print()
    
    print("=" * 60)
    print("âœ… ã™ã¹ã¦ã®å¯è¦–åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print()
    print("ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
    print(f"  1. {understanding_output}  - æ–‡ç« ç†è§£ã®Attentionãƒãƒƒãƒ—")
    print(f"  2. {generation_output}     - æ–‡ç« ç”Ÿæˆã®å„ã‚¹ãƒ†ãƒƒãƒ—")
    print(f"  3. {detail_output} - ç”Ÿæˆã‚¹ãƒ†ãƒƒãƒ—ã®è©³ç´°")
    print("=" * 60)


if __name__ == "__main__":
    main()
